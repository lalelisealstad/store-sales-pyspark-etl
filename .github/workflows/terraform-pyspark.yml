name: Deploy and Run PySpark Job on Dataproc

on:
  push:
    branches:
      - main

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    # Authenticate using the correct auth action
    - name: Authenticate with Google Cloud
      uses: google-github-actions/auth@v1
      with:
        credentials_json: ${{ secrets.GCP_SA_KEY }}  # Use the secret for your service account key

    # Set up Google Cloud SDK without specifying the service account key
    - name: Set up Google Cloud SDK
      uses: google-github-actions/setup-gcloud@v1
      with:
        project_id: "liqour-store-etl"

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v1
      with:
          terraform_version: 1.5.7
    - name: Terraform init and validate
      run: |
          terraform init

    - name: Terraform apply
      run: |
        terraform apply


 #   # Step to upload the PySpark job script from GitHub repo to the GCS bucket
 #   - name: Upload PySpark job to GCS
 #     run: |
 #       gsutil cp pyspark-job.py gs://liquor-store-data-bucket/main.py
#
 #   # Submit the PySpark job to Dataproc
 #   - name: Submit PySpark Job
 #     run: |
 #       gcloud dataproc jobs submit pyspark gs://liquor-store-data-bucket/main.py \
 #         --cluster=liquor-store-dataproc-cluster --region=europe-west1
